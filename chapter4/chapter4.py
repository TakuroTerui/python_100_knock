# -*- coding: utf-8 -*-
"""chapter4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iiCYPqvlMEiJGKM1i69MPCcUP89V_Zri

### ノック31：データを読み込んで確認しよう
"""

import pandas as pd
uselog = pd.read_csv('use_log.csv')
uselog.isnull().sum()

customer = pd.read_csv('customer_join.csv')
customer.isnull().sum()

"""### ノック32：クラスタリングで顧客をグループ化しよう"""

customer_clustering = customer[['mean', 'median', 'max', 'min', 'membership_period']]
customer_clustering.head()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
customer_clustering_sc = sc.fit_transform(customer_clustering)

kmeans = KMeans(n_clusters=4, random_state=0)
clusters = kmeans.fit(customer_clustering_sc)
customer_clustering['cluster'] = clusters.labels_
print(customer_clustering['cluster'].unique())
customer_clustering.head()

"""### ノック33：クラスタリング結果を分析しよう"""

customer_clustering.columns = ['月内平均値', '月内中央値', '月内最大値', '月内最小値', '会員期間', 'cluster']
customer_clustering.groupby('cluster').count()

customer_clustering.groupby('cluster').mean()

"""### ノック34：クラスタリング結果を可視化してみよう"""

from sklearn.decomposition import PCA
X = customer_clustering_sc
pca = PCA(n_components=2)
pca.fit(X)
x_pca = pca.transform(X)
pca_df = pd.DataFrame(x_pca)
pca_df['cluster'] = customer_clustering['cluster']

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

for i in customer_clustering['cluster'].unique():
    tmp = pca_df.loc[pca_df['cluster'] == i]
    plt.scatter(tmp[0], tmp[1])

"""### ノック35：クラスタリング結果をもとに退会顧客の傾向を把握しよう"""

customer_clustering = pd.concat([customer_clustering, customer], axis=1)
customer_clustering.groupby(['cluster', 'is_deleted'], as_index=False).count()[['cluster', 'is_deleted', 'customer_id']]

customer_clustering.groupby(['cluster', 'routine_flg'], as_index=False).count()[['cluster', 'routine_flg', 'customer_id']]

"""### ノック36：翌月の利用回数予測を行うための準備をしよう"""

uselog['usedate'] = pd.to_datetime(uselog['usedate'])
uselog['年月'] = uselog['usedate'].dt.strftime("%Y%m")
uselog_months = uselog.groupby(['年月', 'customer_id'], as_index=False).count()
uselog_months.rename(columns={'log_id':'count'}, inplace=True)
del uselog_months['usedate']
uselog_months.head()

year_months = list(uselog_months["年月"].unique())
predict_data = pd.DataFrame()

for i, year_month in enumerate(year_months[6:], 6):
    predict_data_month = uselog_months.loc[uselog_months["年月"] == year_month] 
    predict_data_month.rename(columns={"count":"count_pred"}, inplace=True)

    for j in range(1, 7):
        past_data = uselog_months.loc[uselog_months["年月"] == year_months[i-j]]
        del past_data["年月"]
        past_data.rename(columns={"count":"count_{}".format(j-1)}, inplace=True)
        predict_data_month = pd.merge(predict_data_month, past_data, on="customer_id", how="left")

    predict_data = pd.concat([predict_data, predict_data_month], ignore_index=True)

predict_data.head()

predict_data = predict_data.dropna()
predict_data = predict_data.reset_index(drop=True)
predict_data.head()

"""### ノック37：特徴となる変数を付与しよう"""

predict_data = pd.merge(predict_data, customer[['customer_id', 'start_date']], on='customer_id', how='left')
predict_data.head()

predict_data['now_date'] = pd.to_datetime(predict_data['年月'], format="%Y%m")
predict_data['start_date'] = pd.to_datetime(predict_data['start_date'])
from dateutil.relativedelta import relativedelta
predict_data['period'] = None
for i in range(len(predict_data)):
    delta = relativedelta(predict_data['now_date'][i], predict_data['start_date'][i])
    predict_data['period'][i] = delta.years * 12 + delta.months
predict_data.head()

"""### ノック38：来月の利用回数予測モデルを作成しよう"""

predict_data = predict_data.loc[predict_data['start_date'] >= pd.to_datetime('20180401')]
from sklearn import linear_model
import sklearn.model_selection
model = linear_model.LinearRegression()
X = predict_data[['count_0', 'count_1', 'count_2', 'count_3', 'count_4', 'count_5', 'period']]
y = predict_data['count_pred']
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)
model.fit(X_train, y_train)

print(model.score(X_train, y_train))
print(model.score(X_test, y_test))

"""### ノック39：モデルに寄与している変数を確認しよう"""

coef = pd.DataFrame({'feature_names':X.columns, 'coefficient':model.coef_})
coef

"""### ノック40：来月の利用回数を予測しよう"""

x1 = [3, 4, 4, 6, 8, 7, 8]
x2 = [2, 2, 3, 3, 4, 6, 8]
x_pred = [x1, x2]

model.predict(x_pred)

uselog_months.to_csv('use_log_months.csv', index=False)