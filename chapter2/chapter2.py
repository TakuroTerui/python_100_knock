# -*- coding: utf-8 -*-
"""chapter2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m7zGUXbkutPMOSqZlPzj7X2FwmHKhJCb

### ノック11：データを読み込んでみよう
"""

import pandas as pd
uriage_data = pd.read_csv('uriage.csv')
uriage_data.head()

kokyaku_data = pd.read_excel('kokyaku_daicho.xlsx')
kokyaku_data.head()

"""### ノック12：データの揺れを見てみよう"""

uriage_data['item_name'].head()

uriage_data['item_price'].head()

"""### ノック13：データに揺れがあるまま集計してみよう"""

uriage_data['purchase_data'] = pd.to_datetime(uriage_data['purchase_date'])
uriage_data['purchase_month'] = uriage_data['purchase_data'].dt.strftime("%Y%m")
res = uriage_data.pivot_table(index='purchase_month', columns='item_name', aggfunc='size', fill_value=0)
res

res = uriage_data.pivot_table(index='purchase_month', columns='item_name', values='item_price', aggfunc='sum', fill_value=0)
res

"""### ノック14：商品名の揺れを補正しよう"""

print(len(pd.unique(uriage_data.item_name)))

uriage_data['item_name'] = uriage_data['item_name'].str.upper()
uriage_data['item_name'] = uriage_data['item_name'].str.replace('　', '')
uriage_data['item_name'] = uriage_data['item_name'].str.replace(' ', '')
uriage_data.sort_values(by=['item_name'], ascending=True)

print(pd.unique(uriage_data.item_name))
print(len(pd.unique(uriage_data.item_name)))

"""### ノック15：金額欠損値の補完しよう"""

uriage_data.isnull().any(axis=0)

flg_is_null = uriage_data['item_price'].isnull()
for trg in list(uriage_data.loc[flg_is_null, 'item_name'].unique()):
    price = uriage_data.loc[(~flg_is_null) & (uriage_data['item_name'] == trg), 'item_price'].max()
    uriage_data['item_price'].loc[(flg_is_null) & (uriage_data['item_name'] == trg)] = price
uriage_data.head()

uriage_data.isnull().any(axis=0)

for trg in list(uriage_data['item_name'].sort_values().unique()):
    print(trg + 'の最大値：' + str(uriage_data.loc[uriage_data['item_name'] == trg]['item_price'].max()))
    print(trg + 'の最小値：' + str(uriage_data.loc[uriage_data['item_name'] == trg]['item_price'].min(skipna=False)))

"""### ノック16：顧客名の揺れを補正しよう"""

kokyaku_data['顧客名'].head()

uriage_data['customer_name'].head()

kokyaku_data['顧客名'] = kokyaku_data['顧客名'].str.replace('　', '')
kokyaku_data['顧客名'] = kokyaku_data['顧客名'].str.replace(' ', '')
kokyaku_data['顧客名'].head()

"""### ノック17：日付の揺れを補正しよう"""

flg_is_serial = kokyaku_data['登録日'].astype('str').str.isdigit()
flg_is_serial.sum()

fromSerial = pd.to_timedelta(kokyaku_data.loc[flg_is_serial, '登録日'].astype('float'), unit="D") + pd.to_datetime('1900/01/01')
fromSerial

fromString = pd.to_datetime(kokyaku_data.loc[~flg_is_serial, '登録日'])
fromString

kokyaku_data['登録日'] = pd.concat([fromSerial, fromString])
kokyaku_data

kokyaku_data['登録年月'] = kokyaku_data['登録日'].dt.strftime("%Y%m")
rslt = kokyaku_data.groupby('登録年月').count()['顧客名']
print(rslt)
print(len(kokyaku_data))

flg_is_serial = kokyaku_data['登録日'].astype('str').str.isdigit()
flg_is_serial.sum()

"""### ノック18：顧客名をキーに2つのデータを結合（ジョイン）しよう"""

join_data = pd.merge(uriage_data, kokyaku_data, left_on='customer_name', right_on='顧客名', how='left')
join_data = join_data.drop('customer_name', axis=1)
join_data

"""### ノック19：クレンジングしたデータをダンプしよう"""

dump_data = join_data[['purchase_date', 'purchase_month', 'item_name', 'item_price', '顧客名', 'かな', '地域', 'メールアドレス', '登録日']]
dump_data

dump_data.to_csv('dump_data.csv', index=False)

import_data = pd.read_csv('dump_data.csv')
import_data

byItem = import_data.pivot_table(index='purchase_month', columns='item_name', aggfunc='size', fill_value=0)
byItem

byPrice = import_data.pivot_table(index='purchase_month', columns='item_name', values='item_price', aggfunc='sum', fill_value=0)
byPrice

byRegion = import_data.pivot_table(index='purchase_month', columns='地域', aggfunc='size', fill_value=0)
byRegion

byCustomer = import_data.pivot_table(index='purchase_month', columns='顧客名', aggfunc='size', fill_value=0)
byCustomer

away_data = pd.merge(uriage_data, kokyaku_data, left_on='customer_name', right_on='顧客名', how='right')
away_data[away_data['purchase_date'].isnull()][['顧客名', 'メールアドレス', '登録日']]